{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-1 Load data\n",
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qt-gqVTMF-Sl"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from import_file import*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Column 1: the ID of the statement ([ID].json).\n",
    "* Column 2: the label.\n",
    "* Column 3: the statement.\n",
    "* Column 4: the subject(s).\n",
    "* Column 5: the speaker.\n",
    "* Column 6: the speaker's job title.\n",
    "* Column 7: the state info.\n",
    "* Column 8: the party affiliation.\n",
    "* Columns 9-13: the total credit history count, including the current statement.\n",
    "    * 9: barely true counts.\n",
    "    * 10: false counts.\n",
    "    * 11: half true counts.\n",
    "    * 12: mostly true counts.\n",
    "    * 13: pants on fire counts.\n",
    "* Column 14: the context (venue / location of the speech or statement).\n",
    "* Column 15: the extracted justification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory of datasets\n",
    "uri_train = Path.cwd() / \"liar_dataset\" / \"train2.tsv\" \n",
    "uri_test = Path.cwd() / \"liar_dataset\" / \"test2.tsv\" \n",
    "uri_valid = Path.cwd() / \"liar_dataset\" / \"valid2.tsv\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the datasets with column names\n",
    "df_train = pd.read_csv(uri_train, delimiter='\\t', quoting=3, header=None, names=[\"json ID\", \"label\", \"statement\", \"subject\", \"speaker\", \"job title\", \"state\", \"party\",\n",
    "                         \"barely true\", \"false\", \"half true\", \"mostly true\", \"pants on fire\", \"context\", \"justification\"])\n",
    "df_test = pd.read_csv(uri_test, delimiter='\\t', quoting=3, header=None, names=[\"json ID\", \"label\", \"statement\", \"subject\", \"speaker\", \"job title\", \"state\", \"party\",\n",
    "                         \"barely true\", \"false\", \"half true\", \"mostly true\", \"pants on fire\", \"context\", \"justification\"])\n",
    "df_valid = pd.read_csv(uri_valid, delimiter='\\t', quoting=3, header=None, names=[\"json ID\", \"label\", \"statement\", \"subject\", \"speaker\", \"job title\", \"state\", \"party\",\n",
    "                         \"barely true\", \"false\", \"half true\", \"mostly true\", \"pants on fire\", \"context\", \"justification\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "74k_E_WzGEjA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10300, 15)\n",
      "(1299, 15)\n",
      "(1284, 15)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of files\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)\n",
    "print(df_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12883, 15)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the train, test and validation files\n",
    "df_raw = pd.concat([df_train, df_test, df_valid], axis=0, sort=False)\n",
    "\n",
    "# Print the shape of df_raw\n",
    "df_raw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for missing labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 47 missing labels in LIAR-PLUS dataset.\n"
     ]
    }
   ],
   "source": [
    "n_missing = df_raw['label'].isnull().sum()\n",
    "print('There are {} missing labels in LIAR-PLUS dataset.'.format(n_missing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47, 15)\n"
     ]
    }
   ],
   "source": [
    "df_raw_missing = df_raw.loc[df_raw['label'].isnull(), : ]\n",
    "print(df_raw_missing.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    json ID label statement subject speaker job title state party  \\\n",
      "NaN     NaN   NaN       NaN     NaN     NaN       NaN   NaN   NaN   \n",
      "NaN     NaN   NaN       NaN     NaN     NaN       NaN   NaN   NaN   \n",
      "NaN     NaN   NaN       NaN     NaN     NaN       NaN   NaN   NaN   \n",
      "NaN     NaN   NaN       NaN     NaN     NaN       NaN   NaN   NaN   \n",
      "NaN     NaN   NaN       NaN     NaN     NaN       NaN   NaN   NaN   \n",
      "\n",
      "     barely true  false  half true  mostly true  pants on fire context  \\\n",
      "NaN          NaN    NaN        NaN          NaN            NaN     NaN   \n",
      "NaN          NaN    NaN        NaN          NaN            NaN     NaN   \n",
      "NaN          NaN    NaN        NaN          NaN            NaN     NaN   \n",
      "NaN          NaN    NaN        NaN          NaN            NaN     NaN   \n",
      "NaN          NaN    NaN        NaN          NaN            NaN     NaN   \n",
      "\n",
      "    justification  \n",
      "NaN           NaN  \n",
      "NaN           NaN  \n",
      "NaN           NaN  \n",
      "NaN           NaN  \n",
      "NaN           NaN  \n"
     ]
    }
   ],
   "source": [
    "# Show some of the rows with missing labels\n",
    "print(df_raw_missing.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove missing labels (if exists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = df_raw.loc[df_raw['label'].notna(), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12836, 15)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the shape of the dataset after removing missing labels\n",
    "df_raw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path.cwd() / \"processed_data\" / \"df_raw.pkl\"\n",
    "df_raw.to_pickle(path)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "faceDetection.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
