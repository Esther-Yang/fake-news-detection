{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qt-gqVTMF-Sl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "\n",
    "from import_file import*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import gutenberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bi = pd.read_pickle('df_bi_A.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifiying features and labels\n",
    "X = df_bi['statement'].values\n",
    "y = df_bi['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10268 2568\n",
      "10268 2568\n"
     ]
    }
   ],
   "source": [
    "# Specifying train and test split with ratio of 80:20\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state = 0, stratify=y)\n",
    "print(len(X_train), len(X_test))\n",
    "print(len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Dimension of vectors we are generating\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "#Creating Word Vectors by Word2Vec Method (takes time...)\n",
    "w2v_model = gensim.models.Word2Vec(sentences=X_train, vector_size=EMBEDDING_DIM, window=5, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w2v_model.wv.key_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Key 'america' not present\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-f025d9d2ff98>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mw2v_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"america\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\anaconda\\envs\\tensorflow_keras_env_3_8\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key_or_keys)\u001b[0m\n\u001b[0;32m    377\u001b[0m         \"\"\"\n\u001b[0;32m    378\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey_or_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKEY_TYPES\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 379\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey_or_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkey_or_keys\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tensorflow_keras_env_3_8\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[1;34m(self, key, norm)\u001b[0m\n\u001b[0;32m    420\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m         \"\"\"\n\u001b[1;32m--> 422\u001b[1;33m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    423\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill_norms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tensorflow_keras_env_3_8\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mget_index\u001b[1;34m(self, key, default)\u001b[0m\n\u001b[0;32m    394\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 396\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Key '{key}' not present\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Key 'america' not present\""
     ]
    }
   ],
   "source": [
    "w2v_model.wv[\"america\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WOrd2vec end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing Text -> Repsesenting each word by a number\n",
    "# Mapping of orginal word to number is preserved in word_index property of tokenizer\n",
    "\n",
    "#Tokenized applies basic processing like changing it yo lower case, explicitely setting that as False\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 208, 324, 640, 1423, 191, 19, 50, 925, 306]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets check the first 10 words of first news\n",
    "#every word has been represented with a number\n",
    "X_train[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the -> 1\n",
      "in -> 2\n",
      "of -> 3\n",
      "to -> 4\n",
      "a -> 5\n",
      "and -> 6\n",
      "says -> 7\n",
      "for -> 8\n",
      "that -> 9\n",
      "is -> 10\n"
     ]
    }
   ],
   "source": [
    "#Lets check few word to numerical replesentation\n",
    "#Mapping is preserved in dictionary -> word_index property of instance\n",
    "word_index = tokenizer.word_index\n",
    "for word, num in word_index.items():\n",
    "    print(f\"{word} -> {num}\")\n",
    "    if num == 10:\n",
    "        break        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For determining size of input...\n",
    "\n",
    "# Making histogram for no of words in news shows that most news article are under 700 words.\n",
    "# Lets keep each news small and truncate all news to 700 while tokenizing\n",
    "plt.hist([len(x) for x in X], bins=500)\n",
    "plt.show()\n",
    "\n",
    "# Its heavily skewed. There are news with 5000 words? Lets truncate these outliers :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12836"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nos = np.array([len(x) for x in X])\n",
    "len(nos[nos  < 700])\n",
    "# Out of 48k news, 44k have less than 700 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'Says the Annies List political group supports third-trimester abortions on demand.'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-96c046dffe83>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#Making all news of size maxlen defined above\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\anaconda\\envs\\tensorflow_keras_env_3_8\\lib\\site-packages\\tensorflow\\python\\keras\\preprocessing\\sequence.py\u001b[0m in \u001b[0;36mpad_sequences\u001b[1;34m(sequences, maxlen, dtype, padding, truncating, value)\u001b[0m\n\u001b[0;32m    154\u001b[0m           \u001b[1;32mor\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcase\u001b[0m \u001b[0mof\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mentry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m   \"\"\"\n\u001b[1;32m--> 156\u001b[1;33m   return sequence.pad_sequences(\n\u001b[0m\u001b[0;32m    157\u001b[0m       \u001b[0msequences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m       padding=padding, truncating=truncating, value=value)\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tensorflow_keras_env_3_8\\lib\\site-packages\\keras_preprocessing\\sequence.py\u001b[0m in \u001b[0;36mpad_sequences\u001b[1;34m(sequences, maxlen, dtype, padding, truncating, value)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[1;31m# check `trunc` has expected shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m         \u001b[0mtrunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtrunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0msample_shape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m             raise ValueError('Shape of sample %s of sequence at position %s '\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tensorflow_keras_env_3_8\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order, like)\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_asarray_with_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlike\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: 'Says the Annies List political group supports third-trimester abortions on demand.'"
     ]
    }
   ],
   "source": [
    "#Lets keep all news to 700, add padding to news with less than 700 words and truncating long ones\n",
    "maxlen = 700 \n",
    "\n",
    "#Making all news of size maxlen defined above\n",
    "X_train = pad_sequences(X, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding 1 because of reserved 0 index\n",
    "# Embedding Layer creates one more vector for \"UNKNOWN\" words, or padded words (0s). This Vector is filled with zeros.\n",
    "# Thus our vocab size inceeases by 1\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create weight matrix from word2vec gensim model\n",
    "def get_weight_matrix(model, vocab):\n",
    "    # total vocabulary size plus 0 for unknown words\n",
    "    vocab_size = len(vocab) + 1\n",
    "    # define weight matrix dimensions with all 0\n",
    "    weight_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\n",
    "    # step vocab, store vectors using the Tokenizer's integer mapping\n",
    "    for word, i in vocab.items():\n",
    "        weight_matrix[i] = model[word]\n",
    "    return weight_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Key 'the' not present\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-abe5bec11921>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Getting embedding vectors from word2vec and usings it as weights of non-trainable keras embedding layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0membedding_vectors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_weight_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw2v_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-37-d9da2bd6ecb8>\u001b[0m in \u001b[0;36mget_weight_matrix\u001b[1;34m(model, vocab)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m# step vocab, store vectors using the Tokenizer's integer mapping\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvocab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mweight_matrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mweight_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tensorflow_keras_env_3_8\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key_or_keys)\u001b[0m\n\u001b[0;32m    377\u001b[0m         \"\"\"\n\u001b[0;32m    378\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey_or_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKEY_TYPES\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 379\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey_or_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkey_or_keys\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tensorflow_keras_env_3_8\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[1;34m(self, key, norm)\u001b[0m\n\u001b[0;32m    420\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m         \"\"\"\n\u001b[1;32m--> 422\u001b[1;33m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    423\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill_norms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tensorflow_keras_env_3_8\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mget_index\u001b[1;34m(self, key, default)\u001b[0m\n\u001b[0;32m    394\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 396\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Key '{key}' not present\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Key 'the' not present\""
     ]
    }
   ],
   "source": [
    "#Getting embedding vectors from word2vec and usings it as weights of non-trainable keras embedding layer\n",
    "embedding_vectors = get_weight_matrix(w2v_model.wv, word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Conv1D, MaxPool1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#invoke garbage collector to free ram\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes RAM \n",
    "word_vectors = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
    "EMBEDDING_DIM=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vocab_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-2786ab9377d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0membedding_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEMBEDDING_DIM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mword_index\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0membedding_vector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword_vectors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0membedding_matrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0membedding_vector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vocab_size' is not defined"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    try:\n",
    "        embedding_vector = word_vectors[word]\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    except KeyError:\n",
    "        embedding_matrix[i]=np.random.normal(0,np.sqrt(0.25),EMBEDDING_DIM)\n",
    "\n",
    "del word_vectors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
